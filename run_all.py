# -*- coding: utf-8 -*-
"""
çµ±åˆå®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ: å±±å£çœŒæ©‹æ¢ç¶­æŒç®¡ç† Agentic Clustering v0.2
è‡ªå·±è©•ä¾¡ã¨æ”¹å–„ã‚’ç¹°ã‚Šè¿”ã™è³¢ã„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ 
"""

import sys
import os

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

import data_preprocessing
import visualization
from agentic_workflow import AgenticClusteringWorkflow
import config

def main():
    """å…¨å‡¦ç†ã‚’é †ç•ªã«å®Ÿè¡Œ"""
    print("\n" + "="*70)
    print("ğŸ¤– æ©‹æ¢ç¶­æŒç®¡ç† Agentic Clustering v0.2")
    print("="*70 + "\n")
    
    try:
        # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†
        print("\n" + "â”€"*70)
        print("ã€ã‚¹ãƒ†ãƒƒãƒ— 1/3ã€‘ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†")
        print("â”€"*70)
        df_processed = data_preprocessing.preprocess_all_data()
        
        if df_processed is None:
            print("\nâŒ ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™ã€‚")
            return False
        
        input("\nâ¸ï¸  ç¶šè¡Œã™ã‚‹ã«ã¯Enterã‚­ãƒ¼ã‚’æŠ¼ã—ã¦ãã ã•ã„...")
        
        # ã‚¹ãƒ†ãƒƒãƒ—2: Agenticã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
        print("\n" + "â”€"*70)
        print("ã€ã‚¹ãƒ†ãƒƒãƒ— 2/3ã€‘Agenticã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ")
        print("â”€"*70)
        
        # ç‰¹å¾´é‡ã‚«ãƒ©ãƒ ã‚’å–å¾—
        feature_cols = [col for col in config.FEATURE_COLUMNS if col in df_processed.columns]
        
        if len(feature_cols) == 0:
            print("\nâŒ ç‰¹å¾´é‡ã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™ã€‚")
            return False
        
        # Agenticãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œ
        workflow = AgenticClusteringWorkflow(df_processed, feature_cols)
        result = workflow.run(
            quality_threshold=config.QUALITY_THRESHOLD,
            overlap_threshold=config.OVERLAP_THRESHOLD
        )
        
        if result is None:
            print("\nâŒ ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™ã€‚")
            return False
        
        # çµæœã‚’ä¿å­˜
        df_with_cluster = result['df_with_cluster']
        cluster_summary = result['cluster_summary']
        
        df_with_cluster.to_csv(config.CLUSTER_RESULT_FILE, index=False, encoding='utf-8-sig')
        cluster_summary.to_csv(config.CLUSTER_SUMMARY_FILE, encoding='utf-8-sig')
        
        print(f"\nğŸ’¾ çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ:")
        print(f"   - {config.CLUSTER_RESULT_FILE}")
        print(f"   - {config.CLUSTER_SUMMARY_FILE}")
        
        # æ”¹å–„ãƒ­ã‚°ã‚’ä¿å­˜
        log_file = os.path.join(config.OUTPUT_DIR, 'agentic_improvement_log.txt')
        with open(log_file, 'w', encoding='utf-8') as f:
            f.write("Agenticã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°æ”¹å–„ãƒ­ã‚°\n")
            f.write("="*70 + "\n\n")
            f.write(f"æœ€é©ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°æ‰‹æ³•: {result['clustering_method']}\n")
            f.write(f"æœ€é©æ¬¡å…ƒå‰Šæ¸›æ‰‹æ³•: {result['dim_reduction_method']}\n\n")
            f.write("æ”¹å–„å±¥æ­´:\n")
            for i, log in enumerate(result['improvement_log'], 1):
                f.write(f"{i}. {log}\n")
            f.write("\nè©•ä¾¡ã‚¹ã‚³ã‚¢:\n")
            for key, value in result['evaluation_scores'].items():
                f.write(f"  {key}: {value}\n")
        
        print(f"   - {log_file}")
        
        input("\nâ¸ï¸  ç¶šè¡Œã™ã‚‹ã«ã¯Enterã‚­ãƒ¼ã‚’æŠ¼ã—ã¦ãã ã•ã„...")
        
        # ã‚¹ãƒ†ãƒƒãƒ—3: å¯è¦–åŒ–
        print("\n" + "â”€"*70)
        print("ã€ã‚¹ãƒ†ãƒƒãƒ— 3/3ã€‘çµæœã®å¯è¦–åŒ–")
        print("â”€"*70)
        
        # 3æ¬¡å…ƒåŸ‹ã‚è¾¼ã¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆUMAPä½¿ç”¨æ™‚ï¼‰
        embedding_3d = None
        if result['dim_reduction_method'] == 'UMAP' and 'embedding_3d' in result:
            embedding_3d = result['embedding_3d']
        
        visualization.main(
            dim_reduction_method=result['dim_reduction_method'],
            embedding=result['embedding'],
            embedding_3d=embedding_3d
        )
        
        # å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        print("\n" + "="*70)
        print("âœ… ã™ã¹ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        print("="*70)
        print("\nğŸ“ çµæœã¯ output/ ãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚")
        print("\næ¬¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„:")
        print("  ğŸ¤– agentic_improvement_log.txt - Agenticã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°æ”¹å–„ãƒ­ã‚°")
        print("  ğŸ“Š cluster_pca_scatter.png - æ•£å¸ƒå›³ï¼ˆæœ€é©æ¬¡å…ƒå‰Šæ¸›æ‰‹æ³•ï¼‰")
        if embedding_3d is not None:
            print("  ğŸŒ cluster_pca_scatter_3d.png - 3æ¬¡å…ƒæ•£å¸ƒå›³ï¼ˆNEW!ï¼‰")
        print("  ğŸ”¥ cluster_heatmap.png - ç‰¹å¾´é‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—")
        print("  ğŸŒ³ cluster_hierarchy.png - ã‚¯ãƒ©ã‚¹ã‚¿éšå±¤æ§‹é€ å›³ï¼ˆNEW!ï¼‰")
        print("  ğŸ“¡ cluster_radar.png - ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ")
        print("  ğŸ“Š cluster_distribution.png - ã‚¯ãƒ©ã‚¹ã‚¿åˆ†å¸ƒ")
        print("  ğŸ“¦ feature_boxplots.png - ç®±ã²ã’å›³")
        print("  ğŸ“ cluster_report.txt - åˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
        print("\nğŸ¯ Agenticã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã«ã‚ˆã‚Šã€æœ€é©ãªæ‰‹æ³•ãŒè‡ªå‹•é¸æŠã•ã‚Œã¾ã—ãŸï¼")
        
        return True
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚Šå‡¦ç†ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸã€‚")
        return False
    
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    
    if success:
        print("\nğŸ‰ åˆ†æãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
    else:
        print("\nğŸ’” åˆ†æã‚’å®Œäº†ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
    
    input("\nçµ‚äº†ã™ã‚‹ã«ã¯Enterã‚­ãƒ¼ã‚’æŠ¼ã—ã¦ãã ã•ã„...")
