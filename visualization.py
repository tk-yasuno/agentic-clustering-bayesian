# -*- coding: utf-8 -*-
"""
å¯è¦–åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ: å±±å£çœŒæ©‹æ¢ç¶­æŒç®¡ç†ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°MVP
- ã‚¯ãƒ©ã‚¹ã‚¿æ•£å¸ƒå›³
- ç‰¹å¾´é‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
- ã‚¯ãƒ©ã‚¹ã‚¿ç‰¹æ€§ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import config
import os

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
try:
    import japanize_matplotlib
    japanize_matplotlib.japanize()
except ImportError:
    print("âš  japanize_matplotlib ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    print("  æ—¥æœ¬èªè¡¨ç¤ºã«ã¯ 'pip install japanize-matplotlib' ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

def load_cluster_results():
    """ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœã‚’èª­ã¿è¾¼ã‚€"""
    print("\n" + "="*60)
    print("ğŸ“‚ ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœã‚’èª­ã¿è¾¼ã¿ä¸­...")
    print("="*60)
    
    try:
        df = pd.read_csv(config.CLUSTER_RESULT_FILE)
        cluster_summary = pd.read_csv(config.CLUSTER_SUMMARY_FILE, index_col=0)
        print(f"âœ“ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(df)}ä»¶")
        return df, cluster_summary
    except FileNotFoundError:
        print("\nâŒ ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        print("å…ˆã« clustering.py ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return None, None
    except Exception as e:
        print(f"\nâŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None, None

def plot_pca_clusters(df, dim_reduction_method='PCA', embedding=None, embedding_3d=None):
    """ã‚¯ãƒ©ã‚¹ã‚¿æ•£å¸ƒå›³ï¼ˆæœ€é©æ¬¡å…ƒå‰Šæ¸›æ‰‹æ³•ã‚’ä½¿ç”¨ï¼‰
    
    Parameters:
    -----------
    df : DataFrame
        ã‚¯ãƒ©ã‚¹ã‚¿ãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿
    dim_reduction_method : str
        æ¬¡å…ƒå‰Šæ¸›æ‰‹æ³•å ('PCA', 't-SNE', 'UMAP')
    embedding : array-like, optional
        2æ¬¡å…ƒåŸ‹ã‚è¾¼ã¿ãƒ‡ãƒ¼ã‚¿ï¼ˆæŒ‡å®šã•ã‚Œãªã„å ´åˆã¯PCAã‚’å®Ÿè¡Œï¼‰
    embedding_3d : array-like, optional
        3æ¬¡å…ƒåŸ‹ã‚è¾¼ã¿ãƒ‡ãƒ¼ã‚¿ï¼ˆæŒ‡å®šã•ã‚ŒãŸå ´åˆã¯3Dãƒ—ãƒ­ãƒƒãƒˆã‚‚ä½œæˆï¼‰
    """
    print(f"\nğŸ“Š {dim_reduction_method}æ•£å¸ƒå›³ã‚’ä½œæˆä¸­...")
    
    # åŸ‹ã‚è¾¼ã¿ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯PCAã‚’å®Ÿè¡Œ
    if embedding is None:
        feature_cols = [col for col in config.FEATURE_COLUMNS if col in df.columns]
        X = df[feature_cols].fillna(0)
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        pca = PCA(n_components=2)
        X_reduced = pca.fit_transform(X_scaled)
        dim_reduction_method = 'PCA'
    else:
        X_reduced = embedding
        pca = None
    
    # ãƒ—ãƒ­ãƒƒãƒˆ
    plt.figure(figsize=config.FIGURE_SIZE)
    
    n_clusters = df['cluster'].nunique()
    colors = plt.colormaps.get_cmap(config.COLOR_PALETTE).resampled(n_clusters)
    
    for cluster_id in sorted(df['cluster'].unique()):
        mask = df['cluster'] == cluster_id
        plt.scatter(X_reduced[mask, 0], X_reduced[mask, 1],
                   c=[colors(cluster_id)],
                   label=f'ã‚¯ãƒ©ã‚¹ã‚¿ {cluster_id}',
                   alpha=0.6,
                   edgecolors='black',
                   linewidth=0.5,
                   s=100)
    
    # è»¸ãƒ©ãƒ™ãƒ«ã¨ã‚¿ã‚¤ãƒˆãƒ«ã‚’æ¬¡å…ƒå‰Šæ¸›æ‰‹æ³•ã«å¿œã˜ã¦è¨­å®š
    if dim_reduction_method == 'PCA' and pca is not None:
        xlabel = f'ç¬¬1ä¸»æˆåˆ† ({pca.explained_variance_ratio_[0]:.1%})'
        ylabel = f'ç¬¬2ä¸»æˆåˆ† ({pca.explained_variance_ratio_[1]:.1%})'
        title = 'æ©‹æ¢ç¶­æŒç®¡ç†ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœï¼ˆPCA 2æ¬¡å…ƒå¯è¦–åŒ–ï¼‰'
    elif dim_reduction_method == 't-SNE':
        xlabel = 't-SNE æˆåˆ† 1'
        ylabel = 't-SNE æˆåˆ† 2'
        title = 'æ©‹æ¢ç¶­æŒç®¡ç†ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœï¼ˆt-SNE 2æ¬¡å…ƒå¯è¦–åŒ–ï¼‰'
    elif dim_reduction_method == 'UMAP':
        xlabel = 'UMAP æˆåˆ† 1'
        ylabel = 'UMAP æˆåˆ† 2'
        title = 'æ©‹æ¢ç¶­æŒç®¡ç†ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœï¼ˆUMAP 2æ¬¡å…ƒå¯è¦–åŒ–ï¼‰'
    else:
        xlabel = 'æˆåˆ† 1'
        ylabel = 'æˆåˆ† 2'
        title = f'æ©‹æ¢ç¶­æŒç®¡ç†ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœï¼ˆ{dim_reduction_method} 2æ¬¡å…ƒå¯è¦–åŒ–ï¼‰'
    
    plt.xlabel(xlabel, fontsize=12)
    plt.ylabel(ylabel, fontsize=12)
    plt.title(title, fontsize=14, fontweight='bold')
    plt.legend(title='ã‚¯ãƒ©ã‚¹ã‚¿', bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    
    output_path = os.path.join(config.OUTPUT_DIR, 'cluster_pca_scatter.png')
    plt.savefig(output_path, dpi=config.FIGURE_DPI, bbox_inches='tight')
    print(f"âœ“ ä¿å­˜å®Œäº†: {output_path}")
    plt.show()
    
    # 3æ¬¡å…ƒãƒ—ãƒ­ãƒƒãƒˆã®ä½œæˆï¼ˆembedding_3dãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰
    if embedding_3d is not None:
        print(f"\nğŸ“Š {dim_reduction_method} 3æ¬¡å…ƒæ•£å¸ƒå›³ã‚’ä½œæˆä¸­...")
        
        from mpl_toolkits.mplot3d import Axes3D
        
        fig = plt.figure(figsize=(12, 9))
        ax = fig.add_subplot(111, projection='3d')
        
        n_clusters = df['cluster'].nunique()
        colors = plt.colormaps.get_cmap(config.COLOR_PALETTE).resampled(n_clusters)
        
        for cluster_id in sorted(df['cluster'].unique()):
            mask = df['cluster'] == cluster_id
            ax.scatter(embedding_3d[mask, 0], 
                      embedding_3d[mask, 1], 
                      embedding_3d[mask, 2],
                      c=[colors(cluster_id)],
                      label=f'ã‚¯ãƒ©ã‚¹ã‚¿ {cluster_id}',
                      alpha=0.6,
                      edgecolors='black',
                      linewidth=0.5,
                      s=50)
        
        ax.set_xlabel(f'{dim_reduction_method} æˆåˆ† 1', fontsize=11, labelpad=10)
        ax.set_ylabel(f'{dim_reduction_method} æˆåˆ† 2', fontsize=11, labelpad=10)
        ax.set_zlabel(f'{dim_reduction_method} æˆåˆ† 3', fontsize=11, labelpad=10)
        ax.set_title(f'æ©‹æ¢ç¶­æŒç®¡ç†ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœï¼ˆ{dim_reduction_method} 3æ¬¡å…ƒå¯è¦–åŒ–ï¼‰', 
                    fontsize=14, fontweight='bold', pad=20)
        ax.legend(title='ã‚¯ãƒ©ã‚¹ã‚¿', bbox_to_anchor=(1.15, 1), loc='upper left')
        ax.grid(True, alpha=0.3)
        
        # è¦–ç‚¹ã‚’èª¿æ•´
        ax.view_init(elev=20, azim=45)
        
        plt.tight_layout()
        
        output_path_3d = os.path.join(config.OUTPUT_DIR, 'cluster_pca_scatter_3d.png')
        plt.savefig(output_path_3d, dpi=config.FIGURE_DPI, bbox_inches='tight')
        print(f"âœ“ ä¿å­˜å®Œäº†: {output_path_3d}")
        plt.show()

def plot_cluster_heatmap(cluster_summary):
    """ã‚¯ãƒ©ã‚¹ã‚¿ç‰¹æ€§ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—"""
    print("\nğŸ”¥ ã‚¯ãƒ©ã‚¹ã‚¿ç‰¹æ€§ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’ä½œæˆä¸­...")
    
    # ç‰¹å¾´é‡ã‚’æ¨™æº–åŒ–ï¼ˆç›¸å¯¾æ¯”è¼ƒç”¨ï¼‰
    scaler = StandardScaler()
    cluster_summary_scaled = pd.DataFrame(
        scaler.fit_transform(cluster_summary),
        columns=cluster_summary.columns,
        index=cluster_summary.index
    )
    
    # ã‚µã‚¤ã‚ºã‚’æ‹¡å¤§ï¼šç¸¦1.5å€ã€æ¨ª2å€ï¼ˆ10â†’20, 6â†’9ï¼‰
    plt.figure(figsize=(20, 9))
    
    sns.heatmap(cluster_summary_scaled.T,
                annot=True,
                fmt='.2f',
                cmap='RdYlGn_r',
                center=0,
                cbar_kws={'label': 'æ¨™æº–åŒ–ã‚¹ã‚³ã‚¢'},
                linewidths=0.5,
                linecolor='white',
                annot_kws={'fontsize': 9})  # æ•°å€¤ã®ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºã‚’æŒ‡å®š
    
    plt.xlabel('ã‚¯ãƒ©ã‚¹ã‚¿', fontsize=12)
    plt.ylabel('ç‰¹å¾´é‡', fontsize=12)
    plt.title('ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã®ç‰¹å¾´é‡æ¯”è¼ƒï¼ˆæ¨™æº–åŒ–ï¼‰', fontsize=14, fontweight='bold')
    plt.tight_layout()
    
    output_path = os.path.join(config.OUTPUT_DIR, 'cluster_heatmap.png')
    plt.savefig(output_path, dpi=config.FIGURE_DPI, bbox_inches='tight')
    print(f"âœ“ ä¿å­˜å®Œäº†: {output_path}")
    plt.show()

def plot_cluster_hierarchy(df, cluster_summary):
    """ã‚¯ãƒ©ã‚¹ã‚¿éšå±¤æ§‹é€ å›³ï¼ˆãƒ‡ãƒ³ãƒ‰ãƒ­ã‚°ãƒ©ãƒ ï¼‰"""
    print("\nğŸŒ³ ã‚¯ãƒ©ã‚¹ã‚¿éšå±¤æ§‹é€ å›³ã‚’ä½œæˆä¸­...")
    
    from scipy.cluster.hierarchy import dendrogram, linkage
    from scipy.spatial.distance import pdist
    
    # ã‚¯ãƒ©ã‚¹ã‚¿ä¸­å¿ƒã‚’ä½¿ã£ã¦éšå±¤çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
    linkage_matrix = linkage(cluster_summary, method='ward')
    
    plt.figure(figsize=(12, 6))
    
    dendrogram(
        linkage_matrix,
        labels=[f'C{i}' for i in cluster_summary.index],
        leaf_font_size=12,
        color_threshold=linkage_matrix[-5, 2] if len(linkage_matrix) > 4 else None,
    )
    
    plt.xlabel('ã‚¯ãƒ©ã‚¹ã‚¿ID', fontsize=12)
    plt.ylabel('è·é›¢ï¼ˆWardæ³•ï¼‰', fontsize=12)
    plt.title('ã‚¯ãƒ©ã‚¹ã‚¿ã®éšå±¤æ§‹é€ ï¼ˆãƒ‡ãƒ³ãƒ‰ãƒ­ã‚°ãƒ©ãƒ ï¼‰', fontsize=14, fontweight='bold')
    plt.grid(axis='y', alpha=0.3)
    plt.tight_layout()
    
    output_path = os.path.join(config.OUTPUT_DIR, 'cluster_hierarchy.png')
    plt.savefig(output_path, dpi=config.FIGURE_DPI, bbox_inches='tight')
    print(f"âœ“ ä¿å­˜å®Œäº†: {output_path}")
    plt.show()

def plot_radar_chart(cluster_summary):
    """ã‚¯ãƒ©ã‚¹ã‚¿ç‰¹æ€§ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ"""
    print("\nğŸ“¡ ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆã‚’ä½œæˆä¸­...")
    
    # ç‰¹å¾´é‡ã‚’0-1ã‚¹ã‚±ãƒ¼ãƒ«ã«æ­£è¦åŒ–
    from sklearn.preprocessing import MinMaxScaler
    scaler = MinMaxScaler()
    cluster_summary_scaled = pd.DataFrame(
        scaler.fit_transform(cluster_summary),
        columns=cluster_summary.columns,
        index=cluster_summary.index
    )
    
    n_clusters = len(cluster_summary_scaled)
    n_features = len(cluster_summary_scaled.columns)
    
    # è§’åº¦ã‚’è¨ˆç®—
    angles = np.linspace(0, 2 * np.pi, n_features, endpoint=False).tolist()
    angles += angles[:1]  # å††ã‚’é–‰ã˜ã‚‹
    
    fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))
    
    colors = plt.colormaps.get_cmap(config.COLOR_PALETTE).resampled(n_clusters)
    
    for i, (cluster_id, row) in enumerate(cluster_summary_scaled.iterrows()):
        values = row.tolist()
        values += values[:1]  # å††ã‚’é–‰ã˜ã‚‹
        
        ax.plot(angles, values, 'o-', linewidth=2, label=f'ã‚¯ãƒ©ã‚¹ã‚¿ {cluster_id}',
                color=colors(i))
        ax.fill(angles, values, alpha=0.25, color=colors(i))
    
    ax.set_xticks(angles[:-1])
    ax.set_xticklabels(cluster_summary_scaled.columns, fontsize=10)
    ax.set_ylim(0, 1)
    ax.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])
    ax.set_yticklabels(['0.2', '0.4', '0.6', '0.8', '1.0'], fontsize=8)
    ax.grid(True)
    
    plt.title('ã‚¯ãƒ©ã‚¹ã‚¿ç‰¹æ€§ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ', fontsize=14, fontweight='bold', pad=20)
    plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))
    plt.tight_layout()
    
    output_path = os.path.join(config.OUTPUT_DIR, 'cluster_radar.png')
    plt.savefig(output_path, dpi=config.FIGURE_DPI, bbox_inches='tight')
    print(f"âœ“ ä¿å­˜å®Œäº†: {output_path}")
    plt.show()

def plot_cluster_distribution(df):
    """ã‚¯ãƒ©ã‚¹ã‚¿åˆ†å¸ƒã®æ¨ªæ£’ã‚°ãƒ©ãƒ•"""
    print("\nğŸ“Š ã‚¯ãƒ©ã‚¹ã‚¿åˆ†å¸ƒã‚’ä½œæˆä¸­...")
    
    cluster_counts = df['cluster'].value_counts().sort_index()
    
    plt.figure(figsize=(8, max(6, len(cluster_counts) * 0.3)))
    
    colors = plt.colormaps.get_cmap(config.COLOR_PALETTE).resampled(len(cluster_counts))
    bars = plt.barh(range(len(cluster_counts)), cluster_counts.values,
                   color=[colors(i) for i in range(len(cluster_counts))],
                   edgecolor='black',
                   linewidth=1.5)
    
    # æ£’ã®å³ã«å€¤ã‚’è¡¨ç¤ºï¼ˆä¿®æ­£ï¼šã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½¿ç”¨ï¼‰
    for i, (cluster_id, count) in enumerate(cluster_counts.items()):
        plt.text(count, i, f' {int(count)} ({count/len(df)*100:.1f}%)',
                va='center', ha='left', fontsize=10, fontweight='bold')
    
    # Yè»¸ã®ãƒ©ãƒ™ãƒ«ã‚’ã‚¯ãƒ©ã‚¹ã‚¿IDã«è¨­å®š
    plt.yticks(range(len(cluster_counts)), [f'ã‚¯ãƒ©ã‚¹ã‚¿ {cid}' for cid in cluster_counts.index])
    
    plt.ylabel('ã‚¯ãƒ©ã‚¹ã‚¿', fontsize=12)
    plt.xlabel('æ©‹æ¢æ•°', fontsize=12)
    plt.title('ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã®æ©‹æ¢åˆ†å¸ƒ', fontsize=14, fontweight='bold')
    plt.grid(axis='x', alpha=0.3)
    plt.tight_layout()
    
    output_path = os.path.join(config.OUTPUT_DIR, 'cluster_distribution.png')
    plt.savefig(output_path, dpi=config.FIGURE_DPI, bbox_inches='tight')
    print(f"âœ“ ä¿å­˜å®Œäº†: {output_path}")
    plt.show()

def plot_feature_boxplots(df):
    """ç‰¹å¾´é‡ã®ã‚¯ãƒ©ã‚¹ã‚¿åˆ¥ç®±ã²ã’å›³ï¼ˆ13ç‰¹å¾´é‡ã™ã¹ã¦ï¼‰"""
    print("\nğŸ“¦ ç‰¹å¾´é‡ã®ç®±ã²ã’å›³ã‚’ä½œæˆä¸­...")
    
    feature_cols = [col for col in config.FEATURE_COLUMNS if col in df.columns]
    n_features = len(feature_cols)
    
    # 13ç‰¹å¾´é‡ã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã€5è¡Œ3åˆ—ã®ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã«å¤‰æ›´
    fig, axes = plt.subplots(5, 3, figsize=(18, 20))
    axes = axes.flatten()
    
    for i, feature in enumerate(feature_cols):
        if i < len(axes):
            df.boxplot(column=feature, by='cluster', ax=axes[i])
            axes[i].set_title(feature, fontsize=12, fontweight='bold')
            axes[i].set_xlabel('ã‚¯ãƒ©ã‚¹ã‚¿', fontsize=10)
            axes[i].set_ylabel('å€¤', fontsize=10)
            axes[i].get_figure().suptitle('')  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¿ã‚¤ãƒˆãƒ«ã‚’å‰Šé™¤
    
    # ä½¿ã‚ãªã„è»¸ã‚’éè¡¨ç¤º
    for i in range(n_features, len(axes)):
        axes[i].set_visible(False)
    
    plt.suptitle('ç‰¹å¾´é‡ã®ã‚¯ãƒ©ã‚¹ã‚¿åˆ¥åˆ†å¸ƒ', fontsize=14, fontweight='bold', y=1.00)
    plt.tight_layout()
    
    output_path = os.path.join(config.OUTPUT_DIR, 'feature_boxplots.png')
    plt.savefig(output_path, dpi=config.FIGURE_DPI, bbox_inches='tight')
    print(f"âœ“ ä¿å­˜å®Œäº†: {output_path}")
    plt.show()

def create_cluster_report(df, cluster_summary):
    """ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã§å‡ºåŠ›"""
    print("\nğŸ“ ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆä¸­...")
    
    output_path = os.path.join(config.OUTPUT_DIR, 'cluster_report.txt')
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write("="*70 + "\n")
        f.write("æ©‹æ¢ç¶­æŒç®¡ç†ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°åˆ†æãƒ¬ãƒãƒ¼ãƒˆ\n")
        f.write("="*70 + "\n\n")
        
        # ã‚¯ãƒ©ã‚¹ã‚¿åˆ†å¸ƒ
        f.write("ã€ã‚¯ãƒ©ã‚¹ã‚¿åˆ†å¸ƒã€‘\n")
        cluster_counts = df['cluster'].value_counts().sort_index()
        for cluster_id, count in cluster_counts.items():
            f.write(f"  ã‚¯ãƒ©ã‚¹ã‚¿ {cluster_id}: {count}ä»¶ ({count/len(df)*100:.1f}%)\n")
        f.write(f"\n  åˆè¨ˆ: {len(df)}ä»¶\n\n")
        
        # ã‚¯ãƒ©ã‚¹ã‚¿ç‰¹æ€§
        f.write("ã€ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã®ç‰¹å¾´é‡å¹³å‡ã€‘\n")
        f.write(cluster_summary.to_string())
        f.write("\n\n")
        
        # ã‚¯ãƒ©ã‚¹ã‚¿è§£é‡ˆ
        f.write("ã€ã‚¯ãƒ©ã‚¹ã‚¿è§£é‡ˆã€‘\n")
        for cluster_id in cluster_summary.index:
            row = cluster_summary.loc[cluster_id]
            f.write(f"\nâ–  ã‚¯ãƒ©ã‚¹ã‚¿ {cluster_id}\n")
            
            # å„ç‰¹å¾´é‡ã®å€¤ã‚’è¨˜è¿°
            for col in cluster_summary.columns:
                f.write(f"  - {col}: {row[col]:.2f}\n")
            
            # ãƒªã‚¹ã‚¯è©•ä¾¡
            high_risk_factors = []
            if 'bridge_age' in cluster_summary.columns and row['bridge_age'] > 50:
                high_risk_factors.append("é«˜æ©‹é½¢")
            if 'condition_score' in cluster_summary.columns and row['condition_score'] >= 3:
                high_risk_factors.append("å¥å…¨åº¦ä½ä¸‹")
            if 'maintenance_priority' in cluster_summary.columns and row['maintenance_priority'] > 100:
                high_risk_factors.append("é«˜è£œä¿®å„ªå…ˆåº¦")
            if 'population_decline' in cluster_summary.columns and row['population_decline'] > 15:
                high_risk_factors.append("äººå£æ¸›å°‘")
            if 'aging_rate' in cluster_summary.columns and row['aging_rate'] > 35:
                high_risk_factors.append("é«˜é½¢åŒ–")
            if 'fiscal_index' in cluster_summary.columns and row['fiscal_index'] < 0.5:
                high_risk_factors.append("è²¡æ”¿åŠ›å¼±")
            
            if len(high_risk_factors) >= 3:
                risk_level = "ğŸ”´ é«˜ãƒªã‚¹ã‚¯"
            elif len(high_risk_factors) >= 2:
                risk_level = "ğŸŸ¡ ä¸­ãƒªã‚¹ã‚¯"
            else:
                risk_level = "ğŸŸ¢ ä½ãƒªã‚¹ã‚¯"
            
            f.write(f"\n  ã€è©•ä¾¡ã€‘{risk_level}\n")
            if high_risk_factors:
                f.write(f"  ã€è¦å› ã€‘{', '.join(high_risk_factors)}\n")
        
        f.write("\n" + "="*70 + "\n")
    
    print(f"âœ“ ä¿å­˜å®Œäº†: {output_path}")

def main(dim_reduction_method='PCA', embedding=None, embedding_3d=None):
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†
    
    Parameters:
    -----------
    dim_reduction_method : str
        æ¬¡å…ƒå‰Šæ¸›æ‰‹æ³•å ('PCA', 't-SNE', 'UMAP')
    embedding : array-like, optional
        2æ¬¡å…ƒåŸ‹ã‚è¾¼ã¿ãƒ‡ãƒ¼ã‚¿
    embedding_3d : array-like, optional
        3æ¬¡å…ƒåŸ‹ã‚è¾¼ã¿ãƒ‡ãƒ¼ã‚¿
    """
    print("\n" + "="*60)
    print("ğŸ“Š ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœã®å¯è¦–åŒ–")
    print("="*60)
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    df, cluster_summary = load_cluster_results()
    if df is None or cluster_summary is None:
        return
    
    # å„ç¨®å¯è¦–åŒ–
    plot_pca_clusters(df, dim_reduction_method=dim_reduction_method, 
                     embedding=embedding, embedding_3d=embedding_3d)
    plot_cluster_heatmap(cluster_summary)
    plot_cluster_hierarchy(df, cluster_summary)
    plot_radar_chart(cluster_summary)
    plot_cluster_distribution(df)
    plot_feature_boxplots(df)
    
    # ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
    create_cluster_report(df, cluster_summary)
    
    print("\n" + "="*60)
    print("âœ… å¯è¦–åŒ–å®Œäº†ï¼")
    print("="*60)
    print(f"\nğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:")
    print(f"   {config.OUTPUT_DIR}/")
    print(f"     - cluster_pca_scatter.png")
    if embedding_3d is not None:
        print(f"     - cluster_pca_scatter_3d.png (NEW!)")
    print(f"     - cluster_heatmap.png")
    print(f"     - cluster_hierarchy.png (NEW!)")
    print(f"     - cluster_radar.png")
    print(f"     - cluster_distribution.png")
    print(f"     - feature_boxplots.png")
    print(f"     - cluster_report.txt")

if __name__ == "__main__":
    main()
